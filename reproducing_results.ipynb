{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import lifelines\n",
    "from lifelines.utils import to_long_format\n",
    "from lifelines.utils import add_covariate_to_timeline\n",
    "from lifelines import CoxTimeVaryingFitter\n",
    "\n",
    "from scipy.stats import wilcoxon, friedmanchisquare, kruskal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (5, 5)})\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boxplot_props = {\n",
    "    \"boxprops\": {\"facecolor\": \"none\", \"edgecolor\": (0.25, 0.25, 0.25)},\n",
    "    \"medianprops\": {\"color\": (0.25, 0.25, 0.25)},\n",
    "    \"whiskerprops\": {\"color\": (0.25, 0.25, 0.25)},\n",
    "    \"capprops\": {\"color\": (0.25, 0.25, 0.25)},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTSW retrospective cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "emboli_data = pd.read_excel(\"data/Supplementary Table 3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "emboli_data[\"Medium_Large_Art\"] = emboli_data[\"Medium_Art\"] + emboli_data[\"Large_Art\"]\n",
    "emboli_data[\"Medium_Large_Vein\"] = (\n",
    "    emboli_data[\"Medium_Vein\"] + emboli_data[\"Large_Vein\"]\n",
    ")\n",
    "\n",
    "emboli_data = emboli_data.drop(\n",
    "    columns=[\"Medium_Art\", \"Large_Art\", \"Medium_Vein\", \"Large_Vein\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pt_emboli_data = emboli_data.groupby([\"Patient_ID\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vals = []\n",
    "labs = []\n",
    "hues = []\n",
    "\n",
    "vars_ = [\n",
    "    \"Medium_Large_Art\",\n",
    "    \"Small_Art\",\n",
    "    \"Medium_Large_Vein\",\n",
    "    \"Small_Vein\",\n",
    "]\n",
    "var_labels = [\n",
    "    \"Medium/Large Artery\",\n",
    "    \"Small Artery\",\n",
    "    \"Medium/Large Vein\",\n",
    "    \"Small Vein\",\n",
    "]\n",
    "hue_categories = [\"Artery\", \"Artery\", \"Vein\", \"Vein\"]\n",
    "\n",
    "for row in pt_emboli_data.iterrows():\n",
    "    for var, var_label, hue_cat in zip(vars_, var_labels, hue_categories):\n",
    "        vals.append(row[1][var])\n",
    "        labs.append(var_label)\n",
    "        hues.append(hue_cat)\n",
    "\n",
    "vals = np.array(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "size_classes = [\"Medium_Large\", \"Small\", \"Medium_Large\", \"Small\"]\n",
    "vessel_classes = [\"Artery\", \"Artery\", \"Vein\", \"Vein\"]\n",
    "\n",
    "all_pts = list(set(emboli_data[\"Patient_ID\"]))\n",
    "\n",
    "dists = [[0, 0, 0, 0] for _pt in all_pts]\n",
    "\n",
    "for row in emboli_data.iterrows():\n",
    "    this_pt = row[1][\"Patient_ID\"]\n",
    "    dists_idx = all_pts.index(this_pt)\n",
    "\n",
    "    for idx, var in enumerate(vars_):\n",
    "        if not pd.isnull(row[1][var]):\n",
    "            dists[dists_idx][idx] += row[1][var]\n",
    "\n",
    "dists = np.array(dists).T\n",
    "\n",
    "friedman_res = friedmanchisquare(*dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pairwise_wilcoxon_results = []\n",
    "\n",
    "for idx_0 in range(len(vars_) - 1):\n",
    "    var_0 = vars_[idx_0]\n",
    "\n",
    "    for idx_1 in range(idx_0 + 1, len(vars)):\n",
    "        var_1 = vars_[idx_1]\n",
    "\n",
    "        delta = dists[idx_1] - dists[idx_0]\n",
    "        n_pts_w_increase = len([it for it in delta if it > 0])\n",
    "\n",
    "        res = wilcoxon(delta, alternative=\"two-sided\")\n",
    "        pairwise_wilcoxon_results.append(\n",
    "            (\n",
    "                var_0,\n",
    "                var_1,\n",
    "                res.pvalue,\n",
    "                np.median(delta),\n",
    "                np.mean(delta),\n",
    "                n_pts_w_increase,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vals += 1\n",
    "vals = np.log10(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "p = sns.boxplot(\n",
    "    x=labs, y=vals, saturation=0.8, color=\"white\", fliersize=0, **boxplot_props\n",
    ")\n",
    "b = sns.stripplot(\n",
    "    x=labs,\n",
    "    y=vals,\n",
    "    alpha=0.7,\n",
    "    hue=hues,\n",
    "    size=6,\n",
    ")\n",
    "\n",
    "_ = plt.ylabel(\"Number of tumor emboli\\n(log(count + 1))\")\n",
    "\n",
    "\n",
    "############## anns\n",
    "ylim = plt.ylim()\n",
    "\n",
    "stat_annotations_y_start = ylim[0] + (ylim[1] - ylim[0]) / 2.5\n",
    "stat_annotations_y_start *= 1.4\n",
    "height = (ylim[1] - ylim[0]) / 6\n",
    "\n",
    "height_adj_idx = 0\n",
    "\n",
    "for (\n",
    "    var_0,\n",
    "    var_1,\n",
    "    pval,\n",
    "    _median_delta,\n",
    "    _mean_delta,\n",
    "    _n_pts_w_increase,\n",
    ") in pairwise_wilcoxon_results:\n",
    "    if pval < 0.0005:\n",
    "        pval = f\"p={pval:.2e}\"\n",
    "    else:\n",
    "        pval = f\"p={pval:.3f}\"\n",
    "    x1, x2 = vars_.index(var_0), vars_.index(var_1)\n",
    "\n",
    "    y = stat_annotations_y_start + height * height_adj_idx\n",
    "    h = (ylim[1] - ylim[0]) / 30\n",
    "\n",
    "    plt.plot([x1, x1, x2, x2], [y + h, y + (2 * h), y + (2 * h), y + h], lw=1.5, c=\"k\")\n",
    "    plt.text((x1 + x2) * 0.5, y + (2.5 * h), pval, ha=\"center\", va=\"bottom\", color=\"k\")\n",
    "\n",
    "    height_adj_idx += 1\n",
    "\n",
    "#########################\n",
    "\n",
    "# set y tick labels\n",
    "_ = plt.yticks(\n",
    "    [0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "_ = p.set_ylim(-0.1, 3)\n",
    "_ = p.set_yticklabels([\"$10^0$\", \"$10^1$\", \"$10^2$\", \"$10^3$\"])\n",
    "\n",
    "xticklabels = p.get_xticklabels()\n",
    "xticklabels = [\" \".join(it.get_text().split()[:-1]) for it in xticklabels]\n",
    "\n",
    "_ = p.set_xticks(np.arange(len(xticklabels)))\n",
    "_ = p.set_xticklabels(xticklabels, rotation=45, ha=\"right\")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(\n",
    "    f\"Overall: Friedman test p={friedman_res.pvalue:.2e}\\n\"\n",
    "    f\"Annotations are for Wilcoxon pairwise comparisons\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTSW prospective cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "utsw_prospective_df = pd.read_excel(\"data/Supplementary Table 7.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "premortem_data = {}\n",
    "postmortem_data = {}\n",
    "\n",
    "for _idx, row in utsw_prospective_df.iterrows():\n",
    "    if row[\"Cohort\"] == \"Control\":\n",
    "        continue\n",
    "\n",
    "    pt = row[\"Patient\"]\n",
    "    visit = row[\"Visit\"]\n",
    "\n",
    "    if visit == \"Post-Mortem\":\n",
    "        postmortem_data[pt] = {\n",
    "            \"Total CTCs\": row[\"Total FITC+ CTCs (count/ml)\"],\n",
    "            \"CTC cluster size\": row[\"Mean CTC cluster size: overall\"],\n",
    "            \"Total CTC clusters\": row[\"Total FITC+ CTC clusters (count/ml)\"],\n",
    "            \"Single CTCs\": row[\"Single FITC+ CTCs (count/ml)\"],\n",
    "            \"Homotypic clusters\": row[\"Homotypic FITC+ CTC clusters (count/ml)\"],\n",
    "            \"Heterotypic clusters\": row[\"Heterotypic FITC+ CTC clusters (count/ml)\"],\n",
    "        }\n",
    "    else:\n",
    "        if pt not in premortem_data:\n",
    "            premortem_data[pt] = []\n",
    "\n",
    "        premortem_data[pt].append(\n",
    "            {\n",
    "                \"visit\": visit,\n",
    "                \"Total CTCs\": row[\"Total FITC+ CTCs (count/ml)\"],\n",
    "                \"CTC cluster size\": row[\"Mean CTC cluster size\"],\n",
    "                \"Total CTC clusters\": row[\"Total FITC+ CTC clusters (count/ml)\"],\n",
    "                \"Single CTCs\": row[\"Single FITC+ CTCs (count/ml)\"],\n",
    "                \"Homotypic clusters\": row[\"Homotypic FITC+ CTC clusters (count/ml)\"],\n",
    "                \"Heterotypic clusters\": row[\n",
    "                    \"Heterotypic FITC+ CTC clusters (count/ml)\"\n",
    "                ],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "labs = []\n",
    "\n",
    "test_vector = []\n",
    "var = \"Total CTCs\"\n",
    "\n",
    "for pt in premortem_data:\n",
    "    this_ctc_data = [it for it in premortem_data[pt] if not pd.isnull(it[var])]\n",
    "    this_ctc_data = sorted(this_ctc_data, key=lambda it: it[\"visit\"])\n",
    "\n",
    "    for idx, data_dict in enumerate(this_ctc_data):\n",
    "        timepoint = -1 * (len(this_ctc_data) - idx)\n",
    "\n",
    "        # we are only visualizing timepoints -3 to 0 in these plots, but you will notice that\n",
    "        # the test vector uses the first available timepoint. In any case, this would only\n",
    "        # potentially affect a single case and would have no effect on outcome\n",
    "        if timepoint > -4:\n",
    "            x.append(timepoint)\n",
    "            y.append(data_dict[var])\n",
    "            labs.append(pt)\n",
    "\n",
    "    postmortem_val = postmortem_data[pt][var]\n",
    "\n",
    "    if not pd.isnull(postmortem_val):\n",
    "        x.append(0)\n",
    "        y.append(postmortem_val)\n",
    "        labs.append(pt)\n",
    "\n",
    "        test_vector.append(postmortem_val - this_ctc_data[0][var])\n",
    "\n",
    "wilcoxon_res = wilcoxon(test_vector, alternative=\"two-sided\")\n",
    "\n",
    "# pad 0 values for visualization in log scale\n",
    "y = np.array(y) + 0.05\n",
    "y = np.log10(y)\n",
    "\n",
    "pal = sns.color_palette([f\"#14140a\" for _ in range(len(premortem_data))])\n",
    "\n",
    "p = sns.lineplot(x=x, y=y, hue=labs, palette=pal, alpha=0.298)\n",
    "\n",
    "c = sns.scatterplot(x=x, y=y, hue=labs, alpha=0.298, s=60, legend=False, palette=pal)\n",
    "\n",
    "d = sns.regplot(\n",
    "    x=x, y=y, scatter=False, ci=None, order=3, line_kws={\"linewidth\": 5}, ax=plt.gca()\n",
    ")\n",
    "\n",
    "_ = plt.yticks(\n",
    "    [-1, 0, 2, 4],\n",
    ")\n",
    "\n",
    "# set y tick labels\n",
    "_ = p.set_yticklabels([\"\", \"$10^0$\", \"$10^2$\", \"$10^4$\"])\n",
    "\n",
    "_ = plt.ylim(-1.5, 4)\n",
    "_ = plt.xticks([-3, -2, -1, 0])\n",
    "\n",
    "# remove legend\n",
    "_ = plt.legend([], [], frameon=False)\n",
    "\n",
    "_ = plt.xlabel(\"Pt visits before death\")\n",
    "_ = plt.ylabel(\"Total CTCs (count/ml)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "counts_y = ylim[0] - (ylim[1] - ylim[0]) * 0.25\n",
    "\n",
    "_ = plt.text(\n",
    "    -4.1,\n",
    "    counts_y,\n",
    "    \"No. Pts\",\n",
    ")\n",
    "_ = plt.text(\n",
    "    -3.05,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -3])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -2.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -2])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -1.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -1])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -0.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == 0])),\n",
    ")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(f\"Wilcoxon p-value: {wilcoxon_res.pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "labs = []\n",
    "\n",
    "test_vector = []\n",
    "var = \"Total CTC clusters\"\n",
    "\n",
    "for pt in premortem_data:\n",
    "    this_ctc_data = [it for it in premortem_data[pt] if not pd.isnull(it[var])]\n",
    "    this_ctc_data = sorted(this_ctc_data, key=lambda it: it[\"visit\"])\n",
    "\n",
    "    for idx, data_dict in enumerate(this_ctc_data):\n",
    "        timepoint = -1 * (len(this_ctc_data) - idx)\n",
    "\n",
    "        if timepoint > -4:\n",
    "            x.append(timepoint)\n",
    "            y.append(data_dict[var])\n",
    "            labs.append(pt)\n",
    "\n",
    "    postmortem_val = postmortem_data[pt][var]\n",
    "\n",
    "    if not pd.isnull(postmortem_val):\n",
    "        x.append(0)\n",
    "        y.append(postmortem_val)\n",
    "        labs.append(pt)\n",
    "\n",
    "        test_vector.append(postmortem_val - this_ctc_data[0][var])\n",
    "\n",
    "wilcoxon_res = wilcoxon(test_vector, alternative=\"two-sided\")\n",
    "\n",
    "# pad 0 values for visualization in log scale\n",
    "y = np.array(y) + 0.05\n",
    "y = np.log10(y)\n",
    "\n",
    "pal = sns.color_palette([f\"#14140a\" for _ in range(len(premortem_data))])\n",
    "\n",
    "p = sns.lineplot(x=x, y=y, hue=labs, palette=pal, alpha=0.298)\n",
    "\n",
    "c = sns.scatterplot(x=x, y=y, hue=labs, alpha=0.298, s=60, legend=False, palette=pal)\n",
    "\n",
    "d = sns.regplot(\n",
    "    x=x, y=y, scatter=False, ci=None, order=3, line_kws={\"linewidth\": 5}, ax=plt.gca()\n",
    ")\n",
    "\n",
    "_ = plt.yticks(\n",
    "    [-1, 0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "# set y tick labels\n",
    "_ = p.set_yticklabels([\"\", \"$10^0$\", \"$10^1$\", \"$10^2$\", \"$10^3$\"])\n",
    "\n",
    "_ = plt.ylim(-1.5, 3)\n",
    "\n",
    "_ = plt.xticks([-3, -2, -1, 0])\n",
    "\n",
    "# remove legend\n",
    "_ = plt.legend([], [], frameon=False)\n",
    "\n",
    "_ = plt.xlabel(\"Pt visits before death\")\n",
    "_ = plt.ylabel(\"Total CTC clusters (count/ml)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "counts_y = ylim[0] - (ylim[1] - ylim[0]) * 0.25\n",
    "\n",
    "_ = plt.text(\n",
    "    -4.1,\n",
    "    counts_y,\n",
    "    \"No. Pts\",\n",
    ")\n",
    "_ = plt.text(\n",
    "    -3.05,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -3])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -2.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -2])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -1.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -1])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -0.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == 0])),\n",
    ")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(f\"Wilcoxon p-value: {wilcoxon_res.pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "labs = []\n",
    "\n",
    "test_vector = []\n",
    "var = \"Single CTCs\"\n",
    "\n",
    "for pt in premortem_data:\n",
    "    this_ctc_data = [it for it in premortem_data[pt] if not pd.isnull(it[var])]\n",
    "    this_ctc_data = sorted(this_ctc_data, key=lambda it: it[\"visit\"])\n",
    "\n",
    "    for idx, data_dict in enumerate(this_ctc_data):\n",
    "        timepoint = -1 * (len(this_ctc_data) - idx)\n",
    "\n",
    "        if timepoint > -4:\n",
    "            x.append(timepoint)\n",
    "            y.append(data_dict[var])\n",
    "            labs.append(pt)\n",
    "\n",
    "    postmortem_val = postmortem_data[pt][var]\n",
    "\n",
    "    if not pd.isnull(postmortem_val):\n",
    "        x.append(0)\n",
    "        y.append(postmortem_val)\n",
    "        labs.append(pt)\n",
    "\n",
    "        test_vector.append(postmortem_val - this_ctc_data[0][var])\n",
    "\n",
    "wilcoxon_res = wilcoxon(test_vector, alternative=\"two-sided\")\n",
    "\n",
    "# pad 0 values for visualization in log scale\n",
    "y = np.array(y) + 0.05\n",
    "y = np.log10(y)\n",
    "\n",
    "pal = sns.color_palette([f\"#14140a\" for _ in range(len(premortem_data))])\n",
    "\n",
    "p = sns.lineplot(x=x, y=y, hue=labs, palette=pal, alpha=0.298)\n",
    "\n",
    "c = sns.scatterplot(x=x, y=y, hue=labs, alpha=0.298, s=60, legend=False, palette=pal)\n",
    "\n",
    "d = sns.regplot(\n",
    "    x=x, y=y, scatter=False, ci=None, order=3, line_kws={\"linewidth\": 5}, ax=plt.gca()\n",
    ")\n",
    "\n",
    "_ = plt.yticks(\n",
    "    [-1, 0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "# set y tick labels\n",
    "_ = p.set_yticklabels([\"\", \"$10^0$\", \"$10^1$\", \"$10^2$\", \"$10^3$\"])\n",
    "\n",
    "_ = plt.ylim(-1.5, 3)\n",
    "\n",
    "_ = plt.xticks([-3, -2, -1, 0])\n",
    "\n",
    "# remove legend\n",
    "_ = plt.legend([], [], frameon=False)\n",
    "\n",
    "_ = plt.xlabel(\"Pt visits before death\")\n",
    "_ = plt.ylabel(\"Single CTCs (count/ml)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "counts_y = ylim[0] - (ylim[1] - ylim[0]) * 0.25\n",
    "\n",
    "_ = plt.text(\n",
    "    -4.1,\n",
    "    counts_y,\n",
    "    \"No. Pts\",\n",
    ")\n",
    "_ = plt.text(\n",
    "    -3.05,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -3])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -2.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -2])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -1.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -1])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -0.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == 0])),\n",
    ")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(f\"Wilcoxon p-value: {wilcoxon_res.pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "labs = []\n",
    "\n",
    "test_vector = []\n",
    "var = \"Homotypic clusters\"\n",
    "\n",
    "for pt in premortem_data:\n",
    "    this_ctc_data = [it for it in premortem_data[pt] if not pd.isnull(it[var])]\n",
    "    this_ctc_data = sorted(this_ctc_data, key=lambda it: it[\"visit\"])\n",
    "\n",
    "    for idx, data_dict in enumerate(this_ctc_data):\n",
    "        timepoint = -1 * (len(this_ctc_data) - idx)\n",
    "\n",
    "        if timepoint > -4:\n",
    "            x.append(timepoint)\n",
    "            y.append(data_dict[var])\n",
    "            labs.append(pt)\n",
    "\n",
    "    postmortem_val = postmortem_data[pt][var]\n",
    "\n",
    "    if not pd.isnull(postmortem_val):\n",
    "        x.append(0)\n",
    "        y.append(postmortem_val)\n",
    "        labs.append(pt)\n",
    "\n",
    "        test_vector.append(postmortem_val - this_ctc_data[0][var])\n",
    "\n",
    "wilcoxon_res = wilcoxon(test_vector, alternative=\"two-sided\")\n",
    "\n",
    "# pad 0 values for visualization in log scale\n",
    "y = np.array(y) + 0.05\n",
    "y = np.log10(y)\n",
    "\n",
    "pal = sns.color_palette([f\"#14140a\" for _ in range(len(premortem_data))])\n",
    "\n",
    "p = sns.lineplot(x=x, y=y, hue=labs, palette=pal, alpha=0.298)\n",
    "\n",
    "c = sns.scatterplot(x=x, y=y, hue=labs, alpha=0.298, s=60, legend=False, palette=pal)\n",
    "\n",
    "d = sns.regplot(\n",
    "    x=x, y=y, scatter=False, ci=None, order=3, line_kws={\"linewidth\": 5}, ax=plt.gca()\n",
    ")\n",
    "\n",
    "_ = plt.yticks(\n",
    "    [\n",
    "        -1,\n",
    "        0,\n",
    "        1,\n",
    "        2,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# set y tick labels\n",
    "_ = p.set_yticklabels(\n",
    "    [\n",
    "        \"\",\n",
    "        \"$10^0$\",\n",
    "        \"$10^1$\",\n",
    "        \"$10^2$\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "_ = plt.ylim(-1.5, 2)\n",
    "\n",
    "_ = plt.xticks([-3, -2, -1, 0])\n",
    "\n",
    "# remove legend\n",
    "_ = plt.legend([], [], frameon=False)\n",
    "\n",
    "_ = plt.xlabel(\"Pt visits before death\")\n",
    "_ = plt.ylabel(f\"{var} (count/ml)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "counts_y = ylim[0] - (ylim[1] - ylim[0]) * 0.25\n",
    "\n",
    "_ = plt.text(\n",
    "    -4.1,\n",
    "    counts_y,\n",
    "    \"No. Pts\",\n",
    ")\n",
    "_ = plt.text(\n",
    "    -3.05,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -3])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -2.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -2])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -1.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -1])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -0.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == 0])),\n",
    ")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(f\"Wilcoxon p-value: {wilcoxon_res.pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "labs = []\n",
    "\n",
    "test_vector = []\n",
    "var = \"Heterotypic clusters\"\n",
    "\n",
    "for pt in premortem_data:\n",
    "    this_ctc_data = [it for it in premortem_data[pt] if not pd.isnull(it[var])]\n",
    "    this_ctc_data = sorted(this_ctc_data, key=lambda it: it[\"visit\"])\n",
    "\n",
    "    for idx, data_dict in enumerate(this_ctc_data):\n",
    "        timepoint = -1 * (len(this_ctc_data) - idx)\n",
    "\n",
    "        if timepoint > -4:\n",
    "            x.append(timepoint)\n",
    "            y.append(data_dict[var])\n",
    "            labs.append(pt)\n",
    "\n",
    "    postmortem_val = postmortem_data[pt][var]\n",
    "\n",
    "    if not pd.isnull(postmortem_val):\n",
    "        x.append(0)\n",
    "        y.append(postmortem_val)\n",
    "        labs.append(pt)\n",
    "\n",
    "        test_vector.append(postmortem_val - this_ctc_data[0][var])\n",
    "\n",
    "wilcoxon_res = wilcoxon(test_vector, alternative=\"two-sided\")\n",
    "\n",
    "# pad 0 values for visualization in log scale\n",
    "y = np.array(y) + 0.05\n",
    "y = np.log10(y)\n",
    "\n",
    "pal = sns.color_palette([f\"#14140a\" for _ in range(len(premortem_data))])\n",
    "\n",
    "p = sns.lineplot(x=x, y=y, hue=labs, palette=pal, alpha=0.298)\n",
    "\n",
    "c = sns.scatterplot(x=x, y=y, hue=labs, alpha=0.298, s=60, legend=False, palette=pal)\n",
    "\n",
    "d = sns.regplot(\n",
    "    x=x, y=y, scatter=False, ci=None, order=3, line_kws={\"linewidth\": 5}, ax=plt.gca()\n",
    ")\n",
    "\n",
    "_ = plt.yticks(\n",
    "    [-1, 0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "# set y tick labels\n",
    "_ = p.set_yticklabels([\"\", \"$10^0$\", \"$10^1$\", \"$10^2$\", \"$10^3$\"])\n",
    "\n",
    "_ = plt.ylim(-1.5, 3)\n",
    "\n",
    "_ = plt.xticks([-3, -2, -1, 0])\n",
    "\n",
    "# remove legend\n",
    "_ = plt.legend([], [], frameon=False)\n",
    "\n",
    "_ = plt.xlabel(\"Pt visits before death\")\n",
    "_ = plt.ylabel(f\"{var} (count/ml)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "counts_y = ylim[0] - (ylim[1] - ylim[0]) * 0.25\n",
    "\n",
    "_ = plt.text(\n",
    "    -4.1,\n",
    "    counts_y,\n",
    "    \"No. Pts\",\n",
    ")\n",
    "_ = plt.text(\n",
    "    -3.05,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -3])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -2.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -2])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -1.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -1])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -0.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == 0])),\n",
    ")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(f\"Wilcoxon p-value: {wilcoxon_res.pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "labs = []\n",
    "\n",
    "test_vector = []\n",
    "var = \"CTC cluster size\"\n",
    "\n",
    "for pt in premortem_data:\n",
    "    this_ctc_data = sorted(premortem_data[pt], key=lambda it: it[\"visit\"])\n",
    "    premortem_vals = []\n",
    "\n",
    "    for idx, data_dict in enumerate(this_ctc_data):\n",
    "        timepoint = -1 * (len(this_ctc_data) - idx)\n",
    "\n",
    "        if timepoint > -4 and not pd.isnull(data_dict[var]):\n",
    "            x.append(timepoint)\n",
    "            y.append(data_dict[var])\n",
    "            labs.append(pt)\n",
    "\n",
    "            premortem_vals.append(data_dict[var])\n",
    "\n",
    "    postmortem_val = postmortem_data[pt][var]\n",
    "\n",
    "    if not pd.isnull(postmortem_val):\n",
    "        x.append(0)\n",
    "        y.append(postmortem_val)\n",
    "        labs.append(pt)\n",
    "\n",
    "        if len(this_ctc_data) > 0 and len(premortem_vals) > 0:\n",
    "            test_vector.append(postmortem_val - premortem_vals[0])\n",
    "\n",
    "wilcoxon_res = wilcoxon(test_vector, alternative=\"two-sided\")\n",
    "\n",
    "# pad 0 values for visualization in log scale\n",
    "y = np.array(y) + 0.05\n",
    "y = np.log10(y)\n",
    "\n",
    "pal = sns.color_palette([f\"#14140a\" for _ in range(len(premortem_data))])\n",
    "\n",
    "p = sns.lineplot(x=x, y=y, hue=labs, palette=pal, alpha=0.298)\n",
    "\n",
    "c = sns.scatterplot(x=x, y=y, hue=labs, alpha=0.298, s=60, legend=False, palette=pal)\n",
    "\n",
    "d = sns.regplot(\n",
    "    x=x, y=y, scatter=False, ci=None, order=2, line_kws={\"linewidth\": 5}, ax=plt.gca()\n",
    ")\n",
    "\n",
    "_ = plt.yticks(\n",
    "    [0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "# set y tick labels\n",
    "_ = p.set_yticklabels(\n",
    "    [\n",
    "        \"$10^0$\",\n",
    "        \"$10^1$\",\n",
    "        \"$10^2$\",\n",
    "        \"$10^3$\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "_ = plt.ylim(-0.1, 3)\n",
    "_ = plt.xticks([-3, -2, -1, 0])\n",
    "\n",
    "# remove legend\n",
    "_ = plt.legend([], [], frameon=False)\n",
    "\n",
    "_ = plt.xlabel(\"Pt visits before death\")\n",
    "_ = plt.ylabel(\"CTC cluster size (mean) (count/ml)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "counts_y = ylim[0] - (ylim[1] - ylim[0]) * 0.25\n",
    "\n",
    "_ = plt.text(\n",
    "    -4.1,\n",
    "    counts_y,\n",
    "    \"No. Pts\",\n",
    ")\n",
    "_ = plt.text(\n",
    "    -3.05,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -3])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -2.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -2])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -1.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == -1])),\n",
    ")\n",
    "_ = plt.text(\n",
    "    -0.1,\n",
    "    counts_y,\n",
    "    str(len([it for it in x if it == 0])),\n",
    ")\n",
    "\n",
    "_ = p.spines[\"top\"].set_visible(False)\n",
    "_ = p.spines[\"right\"].set_visible(False)\n",
    "\n",
    "_ = plt.title(f\"Wilcoxon p-value: {wilcoxon_res.pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German retrospective cohort\n",
    "\n",
    "## Survival analyses\n",
    "Logic for the time-varying covariate Cox regression is based on the [`lifelines` documentation](https://lifelines.readthedocs.io/en/latest/Time%20varying%20survival%20regression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "german_df = pd.read_excel(\"data/Supplementary Table 11.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# i do this because i don't enjoy pandas\n",
    "for idx, row in german_df.iterrows():\n",
    "    vital_status = row[\"Vital status\"]\n",
    "\n",
    "    if vital_status == \"Alive\":\n",
    "        vital_status = 0\n",
    "    elif vital_status == \"Deceased\":\n",
    "        vital_status = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected vital status: {vital_status}\")\n",
    "\n",
    "    sex = 0\n",
    "\n",
    "    if row[\"Sex\"] == \"M\":\n",
    "        sex = 1\n",
    "\n",
    "    vessel_times = []\n",
    "\n",
    "    for vessel in range(1, 5):\n",
    "        vessel_col = f\"Vessel {vessel} involvement\"\n",
    "\n",
    "        if row[vessel_col] == 1:\n",
    "            imaging_time_cols = []\n",
    "\n",
    "            for imaging_idx in range(1, 10):\n",
    "                this_imaging_time_col = f\"Vessel {vessel} Imaging time {imaging_idx} time to involvement (days)\"\n",
    "                if this_imaging_time_col in row:\n",
    "                    imaging_time_cols.append(this_imaging_time_col)\n",
    "\n",
    "            final_imaging_time_col = (\n",
    "                f\"Vessel {vessel} LAST AVAILABLE STUDY time to involvement (days)\"\n",
    "            )\n",
    "\n",
    "            if final_imaging_time_col in row:\n",
    "                imaging_time_cols.append(final_imaging_time_col)\n",
    "\n",
    "            involvement_times = [\n",
    "                row[it] for it in imaging_time_cols if pd.notnull(row[it])\n",
    "            ]\n",
    "            earliest_involvement = min(involvement_times)\n",
    "\n",
    "            vessel_times.append((row[f\"Vessel {vessel} type\"], earliest_involvement))\n",
    "\n",
    "    earliest_vessel = None\n",
    "\n",
    "    if len(vessel_times) > 0:\n",
    "        min_time = min([it[1] for it in vessel_times])\n",
    "        earliest_vessel = [it[0] for it in vessel_times if it[1] == min_time]\n",
    "        earliest_vessel = [str(it) for it in earliest_vessel]\n",
    "\n",
    "        if len(earliest_vessel) > 1:\n",
    "            earliest_vessel = \" + \".join(sorted(earliest_vessel))\n",
    "        else:\n",
    "            earliest_vessel = earliest_vessel[0]\n",
    "\n",
    "    data.append(\n",
    "        {\n",
    "            \"pt\": row[\"Censored ID\"],\n",
    "            \"age\": row[\"Age\"],\n",
    "            \"sex\": sex,\n",
    "            \"status\": vital_status,\n",
    "            \"cancer_type\": row[\"Cancer Type\"],\n",
    "            \"time\": row[\"Time to last followup or death (days)\"],\n",
    "            \"delta_to_resection\": row[\"Time to resection (days)\"],\n",
    "            \"delta_to_mets\": row[\"Time to first metastatic lesion (days)\"],\n",
    "            \"delta_to_involvement\": row[\"Time to vessel involvement (days)\"],\n",
    "            \"earliest_vessel\": earliest_vessel,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = []\n",
    "\n",
    "for data_dict in data:\n",
    "    temp_df.append(\n",
    "        {\n",
    "            \"pt\": data_dict[\"pt\"],\n",
    "            \"time\": data_dict[\"time\"],\n",
    "            \"status\": data_dict[\"status\"],\n",
    "            \"age\": data_dict[\"age\"],\n",
    "            \"sex\": data_dict[\"sex\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df = pd.DataFrame(temp_df)\n",
    "temp_df = to_long_format(\n",
    "    temp_df,\n",
    "    duration_col=\"time\",\n",
    ")\n",
    "\n",
    "# add time-varying covariates\n",
    "for dict_var, cv_var in zip(\n",
    "    [\"delta_to_involvement\", \"delta_to_resection\", \"delta_to_mets\"],\n",
    "    [\"vessel_involvement\", \"resection\", \"mets\"],\n",
    "):\n",
    "    cv = []\n",
    "\n",
    "    for data_dict in data:\n",
    "        if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] <= 0:\n",
    "            cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: True})\n",
    "        else:\n",
    "            cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: False})\n",
    "\n",
    "        if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] > 0:\n",
    "            cv.append(\n",
    "                {\"pt\": data_dict[\"pt\"], \"time\": data_dict[dict_var], cv_var: True}\n",
    "            )\n",
    "\n",
    "    cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", cv_var])\n",
    "\n",
    "    temp_df = add_covariate_to_timeline(\n",
    "        temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = temp_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mod = CoxTimeVaryingFitter(penalizer=0.1)\n",
    "_ = mod.fit(temp_df, id_col=\"pt\", event_col=\"status\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mod.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "summary_tables = []\n",
    "\n",
    "for cancer_type in set(german_df[\"Cancer Type\"]):\n",
    "    temp_df = []\n",
    "\n",
    "    for data_dict in data:\n",
    "        if data_dict[\"cancer_type\"] != cancer_type:\n",
    "            continue\n",
    "\n",
    "        this_dict = {\n",
    "            \"pt\": data_dict[\"pt\"],\n",
    "            \"time\": data_dict[\"time\"],\n",
    "            \"status\": data_dict[\"status\"],\n",
    "            \"age\": data_dict[\"age\"],\n",
    "            \"sex\": data_dict[\"sex\"],\n",
    "        }\n",
    "\n",
    "        if cancer_type == \"Ovarian\":\n",
    "            del this_dict[\"sex\"]\n",
    "\n",
    "        temp_df.append(this_dict)\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_df)\n",
    "    temp_df = to_long_format(\n",
    "        temp_df,\n",
    "        duration_col=\"time\",\n",
    "    )\n",
    "\n",
    "    # add time-varying covariates\n",
    "    for dict_var, cv_var in zip(\n",
    "        [\"delta_to_involvement\", \"delta_to_resection\", \"delta_to_mets\"],\n",
    "        [\"vessel_involvement\", \"resection\", \"mets\"],\n",
    "    ):\n",
    "        cv = []\n",
    "\n",
    "        for data_dict in data:\n",
    "            if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] <= 0:\n",
    "                cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: True})\n",
    "            else:\n",
    "                cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: False})\n",
    "\n",
    "            if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] > 0:\n",
    "                cv.append(\n",
    "                    {\"pt\": data_dict[\"pt\"], \"time\": data_dict[dict_var], cv_var: True}\n",
    "                )\n",
    "\n",
    "        cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", cv_var])\n",
    "\n",
    "        temp_df = add_covariate_to_timeline(\n",
    "            temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    "        )\n",
    "\n",
    "    temp_df = temp_df.dropna()\n",
    "\n",
    "    mod = CoxTimeVaryingFitter(penalizer=0.1)\n",
    "    _ = mod.fit(temp_df, id_col=\"pt\", event_col=\"status\", show_progress=False)\n",
    "\n",
    "    summary_tables.append({\"cancer_type\": cancer_type, \"summary\": mod.summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for summary_table in summary_tables:\n",
    "    print(f\"###############################\\n\\n\" f\"{summary_table['cancer_type']}\")\n",
    "    display(summary_table[\"summary\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = []\n",
    "\n",
    "for data_dict in data:\n",
    "    if pd.isnull(data_dict[\"delta_to_mets\"]):\n",
    "        continue\n",
    "\n",
    "    group = \"$V_0$\"\n",
    "\n",
    "    if (\n",
    "        not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "        and data_dict[\"delta_to_involvement\"] <= data_dict[\"delta_to_mets\"] + 30\n",
    "    ):\n",
    "        group = \"$V_1$\"\n",
    "\n",
    "    temp_df.append(\n",
    "        {\n",
    "            \"time\": (\n",
    "                data_dict[\"time\"] - data_dict[\"delta_to_mets\"]\n",
    "            ),  # time from metastasis\n",
    "            \"status\": data_dict[\"status\"],\n",
    "            \"group\": group,\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df = pd.DataFrame(temp_df)\n",
    "\n",
    "# Yes, on average, years are 365.2524 days. We use 365 here\n",
    "temp_df[\"time\"] = temp_df[\"time\"] / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "\n",
    "kmf_0 = lifelines.KaplanMeierFitter()\n",
    "kmf_0.fit(\n",
    "    temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"time\"],\n",
    "    event_observed=temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"status\"],\n",
    "    label=f\"$V_0$, n={temp_df.loc[temp_df['group'] == '$V_0$'].shape[0]}\",\n",
    ")\n",
    "kmf_0.plot(\n",
    "    ax=ax,\n",
    "    ci_show=False,\n",
    "    show_censors=True,\n",
    "    linewidth=2.3,\n",
    ")\n",
    "\n",
    "kmf_1 = lifelines.KaplanMeierFitter()\n",
    "kmf_1.fit(\n",
    "    temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"time\"],\n",
    "    event_observed=temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"status\"],\n",
    "    label=f\"$V_1$, n={temp_df.loc[temp_df['group'] == '$V_1$'].shape[0]}\",\n",
    ")\n",
    "kmf_1.plot(ax=ax, ci_show=False, show_censors=True, linewidth=2.3)\n",
    "\n",
    "_ = plt.xlim(0, 5)\n",
    "# add at risk counts\n",
    "lifelines.plotting.add_at_risk_counts(kmf_0, kmf_1, ax=ax)\n",
    "\n",
    "res = lifelines.statistics.logrank_test(\n",
    "    temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"time\"],\n",
    "    temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"time\"],\n",
    "    event_observed_A=temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"status\"],\n",
    "    event_observed_B=temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"status\"],\n",
    ")\n",
    "\n",
    "_ = plt.xlabel(\"Years\")\n",
    "_ = plt.ylabel(\"Survival Probability\")\n",
    "\n",
    "_ = plt.title(\n",
    "    f\"Survival from time of metastasis\\np={res.p_value: 0.3e}\\n\"\n",
    "    f\"Median survival: {round(kmf_0.median_survival_time_, 2)} vs. \"\n",
    "    f\"{round(kmf_1.median_survival_time_, 2)} years\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(5.22 * 5, 6.5))\n",
    "\n",
    "for idx, cancer_type in enumerate(german_df[\"Cancer Type\"].unique()):\n",
    "    temp_df = []\n",
    "\n",
    "    for data_dict in data:\n",
    "        if (\n",
    "            pd.isnull(data_dict[\"delta_to_mets\"])\n",
    "            or data_dict[\"cancer_type\"] != cancer_type\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        group = \"$V_0$\"\n",
    "\n",
    "        if (\n",
    "            not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "            and data_dict[\"delta_to_involvement\"] <= data_dict[\"delta_to_mets\"] + 30\n",
    "        ):\n",
    "            group = \"$V_1$\"\n",
    "\n",
    "        temp_df.append(\n",
    "            {\n",
    "                \"time\": (data_dict[\"time\"] - data_dict[\"delta_to_mets\"]),\n",
    "                \"status\": data_dict[\"status\"],\n",
    "                \"group\": group,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_df)\n",
    "\n",
    "    temp_df[\"time\"] = temp_df[\"time\"] / 365\n",
    "\n",
    "    kmf_0 = lifelines.KaplanMeierFitter()\n",
    "    kmf_0.fit(\n",
    "        temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"time\"],\n",
    "        event_observed=temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"status\"],\n",
    "        label=f\"$V_0$, n={temp_df.loc[temp_df['group'] == '$V_0$'].shape[0]}\",\n",
    "    )\n",
    "    kmf_0.plot(\n",
    "        ax=ax[idx],\n",
    "        ci_show=False,\n",
    "        show_censors=True,\n",
    "        linewidth=2.3,\n",
    "    )\n",
    "\n",
    "    kmf_1 = lifelines.KaplanMeierFitter()\n",
    "    kmf_1.fit(\n",
    "        temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"time\"],\n",
    "        event_observed=temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"status\"],\n",
    "        label=f\"$V_1$, n={temp_df.loc[temp_df['group'] == '$V_1$'].shape[0]}\",\n",
    "    )\n",
    "    kmf_1.plot(ax=ax[idx], ci_show=False, show_censors=True, linewidth=2.3)\n",
    "\n",
    "    _ = plt.xlim(0, 5)\n",
    "    # add at risk counts\n",
    "    lifelines.plotting.add_at_risk_counts(\n",
    "        kmf_0,\n",
    "        kmf_1,\n",
    "        ax=ax[idx],\n",
    "        xticks=[0, 1, 2, 3, 4, 5],\n",
    "        rows_to_show=[\"At risk\", \"Censored\", \"Events\"],\n",
    "    )\n",
    "\n",
    "    res = lifelines.statistics.logrank_test(\n",
    "        temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"time\"],\n",
    "        temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"time\"],\n",
    "        event_observed_A=temp_df.loc[temp_df[\"group\"] == \"$V_0$\"][\"status\"],\n",
    "        event_observed_B=temp_df.loc[temp_df[\"group\"] == \"$V_1$\"][\"status\"],\n",
    "    )\n",
    "\n",
    "    _ = ax[idx].set_xlabel(\"Years\")\n",
    "    _ = ax[idx].set_ylabel(\"Survival Probability\")\n",
    "\n",
    "    _ = ax[idx].set_title(\n",
    "        f\"{cancer_type}\\nSurvival from time of metastasis\\np={res.p_value: 0.3e}\\n\"\n",
    "        f\"Median survival: {round(kmf_0.median_survival_time_, 2)} vs. \"\n",
    "        f\"{round(kmf_1.median_survival_time_, 2)} years\"\n",
    "    )\n",
    "\n",
    "    _ = ax[idx].set_xlim((0, 5))\n",
    "\n",
    "_ = fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for it in data:\n",
    "    if it[\"earliest_vessel\"] not in counts:\n",
    "        counts[it[\"earliest_vessel\"]] = 0\n",
    "\n",
    "    counts[it[\"earliest_vessel\"]] += 1\n",
    "\n",
    "counts = [(k, v) for k, v in counts.items()]\n",
    "counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
    "top_vessels = [it[0] for it in counts[1:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counts[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = []\n",
    "\n",
    "for data_dict in data:\n",
    "    temp_df.append(\n",
    "        {\n",
    "            \"pt\": data_dict[\"pt\"],\n",
    "            \"time\": data_dict[\"time\"],\n",
    "            \"status\": data_dict[\"status\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df = pd.DataFrame(temp_df)\n",
    "temp_df = to_long_format(\n",
    "    temp_df,\n",
    "    duration_col=\"time\",\n",
    ")\n",
    "\n",
    "################## vessel involvement\n",
    "cv = []\n",
    "\n",
    "for data_dict in data:\n",
    "    if (\n",
    "        not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "        and data_dict[\"delta_to_involvement\"] <= 0\n",
    "    ):\n",
    "        this_vessel = \"Other\"\n",
    "\n",
    "        if data_dict[\"earliest_vessel\"] in top_vessels:\n",
    "            this_vessel = f\"{data_dict['earliest_vessel']} only\"\n",
    "\n",
    "        cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, \"vessel_involved\": this_vessel})\n",
    "    else:\n",
    "        cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, \"vessel_involved\": \"None\"})\n",
    "\n",
    "    if (\n",
    "        not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "        and data_dict[\"delta_to_involvement\"] > 0\n",
    "    ):\n",
    "        this_vessel = \"Other\"\n",
    "\n",
    "        if data_dict[\"earliest_vessel\"] in top_vessels:\n",
    "            this_vessel = f\"{data_dict['earliest_vessel']} only\"\n",
    "\n",
    "        cv.append(\n",
    "            {\n",
    "                \"pt\": data_dict[\"pt\"],\n",
    "                \"time\": data_dict[\"delta_to_involvement\"],\n",
    "                \"vessel_involved\": this_vessel,\n",
    "            }\n",
    "        )\n",
    "\n",
    "cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", \"vessel_involved\"])\n",
    "\n",
    "temp_df = add_covariate_to_timeline(\n",
    "    temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = pd.get_dummies(temp_df, columns=[\"vessel_involved\"], drop_first=False)\n",
    "temp_df = temp_df.drop(columns=[\"vessel_involved_None\"])\n",
    "\n",
    "# drop any rows with NaNs from dataset\n",
    "temp_df = temp_df.dropna()\n",
    "\n",
    "temp_df = temp_df.loc[\n",
    "    ~((temp_df[\"start\"] == temp_df[\"stop\"]) & (temp_df[\"start\"] == 0))\n",
    "]\n",
    "\n",
    "mod = CoxTimeVaryingFitter(penalizer=0.1)\n",
    "_ = mod.fit(temp_df, id_col=\"pt\", event_col=\"status\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mod.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = []\n",
    "\n",
    "for data_dict in data:\n",
    "    temp_df.append(\n",
    "        {\n",
    "            \"pt\": data_dict[\"pt\"],\n",
    "            \"time\": data_dict[\"time\"],\n",
    "            \"status\": data_dict[\"status\"],\n",
    "            \"age\": data_dict[\"age\"],\n",
    "            \"sex\": data_dict[\"sex\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df = pd.DataFrame(temp_df)\n",
    "temp_df = to_long_format(\n",
    "    temp_df,\n",
    "    duration_col=\"time\",\n",
    ")\n",
    "\n",
    "################## vessel involvement\n",
    "cv = []\n",
    "\n",
    "for data_dict in data:\n",
    "    if (\n",
    "        not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "        and data_dict[\"delta_to_involvement\"] <= 0\n",
    "    ):\n",
    "        this_vessel = \"Other\"\n",
    "\n",
    "        if data_dict[\"earliest_vessel\"] in top_vessels:\n",
    "            this_vessel = f\"{data_dict['earliest_vessel']} only\"\n",
    "\n",
    "        cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, \"vessel_involved\": this_vessel})\n",
    "    else:\n",
    "        cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, \"vessel_involved\": \"None\"})\n",
    "\n",
    "    if (\n",
    "        not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "        and data_dict[\"delta_to_involvement\"] > 0\n",
    "    ):\n",
    "        this_vessel = \"Other\"\n",
    "\n",
    "        if data_dict[\"earliest_vessel\"] in top_vessels:\n",
    "            this_vessel = f\"{data_dict['earliest_vessel']} only\"\n",
    "\n",
    "        cv.append(\n",
    "            {\n",
    "                \"pt\": data_dict[\"pt\"],\n",
    "                \"time\": data_dict[\"delta_to_involvement\"],\n",
    "                \"vessel_involved\": this_vessel,\n",
    "            }\n",
    "        )\n",
    "\n",
    "cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", \"vessel_involved\"])\n",
    "\n",
    "temp_df = add_covariate_to_timeline(\n",
    "    temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    ")\n",
    "\n",
    "#################### resection and mets\n",
    "for dict_var, cv_var in zip(\n",
    "    [\"delta_to_resection\", \"delta_to_mets\"], [\"resection\", \"mets\"]\n",
    "):\n",
    "    cv = []\n",
    "\n",
    "    for data_dict in data:\n",
    "        if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] <= 0:\n",
    "            cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: True})\n",
    "        else:\n",
    "            cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: False})\n",
    "\n",
    "        if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] > 0:\n",
    "            cv.append(\n",
    "                {\"pt\": data_dict[\"pt\"], \"time\": data_dict[dict_var], cv_var: True}\n",
    "            )\n",
    "\n",
    "    cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", cv_var])\n",
    "\n",
    "    temp_df = add_covariate_to_timeline(\n",
    "        temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_df = pd.get_dummies(temp_df, columns=[\"vessel_involved\"], drop_first=False)\n",
    "temp_df = temp_df.drop(columns=[\"vessel_involved_None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# drop any rows with NaNs from dataset\n",
    "temp_df = temp_df.dropna()\n",
    "\n",
    "mod = CoxTimeVaryingFitter(penalizer=0.1)\n",
    "_ = mod.fit(temp_df, id_col=\"pt\", event_col=\"status\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mod.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## individual cancer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for cancer_type in set(german_df[\"Cancer Type\"]):\n",
    "    counts = {}\n",
    "\n",
    "    for it in [pt for pt in data if pt[\"cancer_type\"] == cancer_type]:\n",
    "\n",
    "        if it[\"earliest_vessel\"] not in counts:\n",
    "            counts[it[\"earliest_vessel\"]] = 0\n",
    "\n",
    "        counts[it[\"earliest_vessel\"]] += 1\n",
    "\n",
    "    counts = [(k, v) for k, v in counts.items()]\n",
    "    counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
    "    top_vessels = [it[0] for it in counts[1:] if it[1] >= 10]\n",
    "\n",
    "    print(\n",
    "        f\"###############################\\n\\n\"\n",
    "        f\"{cancer_type}\\n\"\n",
    "        f\"Top vessels: {', '.join(top_vessels)}\\n\"\n",
    "    )\n",
    "\n",
    "    for k, v in counts[:6]:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    temp_df = []\n",
    "\n",
    "    for data_dict in [pt for pt in data if pt[\"cancer_type\"] == cancer_type]:\n",
    "\n",
    "        this_pt_dict = {\n",
    "            \"pt\": data_dict[\"pt\"],\n",
    "            \"time\": data_dict[\"time\"],\n",
    "            \"status\": data_dict[\"status\"],\n",
    "        }\n",
    "\n",
    "        temp_df.append(this_pt_dict)\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_df)\n",
    "    temp_df = to_long_format(\n",
    "        temp_df,\n",
    "        duration_col=\"time\",\n",
    "    )\n",
    "\n",
    "    ################## vessel involvement\n",
    "    cv = []\n",
    "\n",
    "    for data_dict in [pt for pt in data if pt[\"cancer_type\"] == cancer_type]:\n",
    "        if (\n",
    "            not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "            and data_dict[\"delta_to_involvement\"] <= 0\n",
    "        ):\n",
    "            this_vessel = \"Other\"\n",
    "\n",
    "            if data_dict[\"earliest_vessel\"] in top_vessels:\n",
    "                this_vessel = f\"{data_dict['earliest_vessel']} only\"\n",
    "\n",
    "            cv.append(\n",
    "                {\"pt\": data_dict[\"pt\"], \"time\": 0, \"vessel_involved\": this_vessel}\n",
    "            )\n",
    "        else:\n",
    "            cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, \"vessel_involved\": \"None\"})\n",
    "\n",
    "        if (\n",
    "            not pd.isnull(data_dict[\"delta_to_involvement\"])\n",
    "            and data_dict[\"delta_to_involvement\"] > 0\n",
    "        ):\n",
    "            this_vessel = \"Other\"\n",
    "\n",
    "            if data_dict[\"earliest_vessel\"] in top_vessels:\n",
    "                this_vessel = f\"{data_dict['earliest_vessel']} only\"\n",
    "\n",
    "            cv.append(\n",
    "                {\n",
    "                    \"pt\": data_dict[\"pt\"],\n",
    "                    \"time\": data_dict[\"delta_to_involvement\"],\n",
    "                    \"vessel_involved\": this_vessel,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", \"vessel_involved\"])\n",
    "\n",
    "    temp_df = add_covariate_to_timeline(\n",
    "        temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    "    )\n",
    "\n",
    "    #################### resection and mets\n",
    "    for dict_var, cv_var in zip(\n",
    "        [\"delta_to_resection\", \"delta_to_mets\"], [\"resection\", \"mets\"]\n",
    "    ):\n",
    "        cv = []\n",
    "\n",
    "        for data_dict in [pt for pt in data if pt[\"cancer_type\"] == cancer_type]:\n",
    "            if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] <= 0:\n",
    "                cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: True})\n",
    "            else:\n",
    "                cv.append({\"pt\": data_dict[\"pt\"], \"time\": 0, cv_var: False})\n",
    "\n",
    "            if not pd.isnull(data_dict[dict_var]) and data_dict[dict_var] > 0:\n",
    "                cv.append(\n",
    "                    {\"pt\": data_dict[\"pt\"], \"time\": data_dict[dict_var], cv_var: True}\n",
    "                )\n",
    "\n",
    "        cv = pd.DataFrame(cv, columns=[\"pt\", \"time\", cv_var])\n",
    "\n",
    "        temp_df = add_covariate_to_timeline(\n",
    "            temp_df, cv, id_col=\"pt\", duration_col=\"time\", event_col=\"status\"\n",
    "        )\n",
    "\n",
    "    temp_df = pd.get_dummies(temp_df, columns=[\"vessel_involved\"], drop_first=False)\n",
    "    temp_df = temp_df.drop(columns=[\"vessel_involved_None\"])\n",
    "    # drop any rows with NaNs from dataset\n",
    "    temp_df = temp_df.dropna()\n",
    "\n",
    "    mod = CoxTimeVaryingFitter(penalizer=0.1)\n",
    "    _ = mod.fit(temp_df, id_col=\"pt\", event_col=\"status\", show_progress=False)\n",
    "\n",
    "    display(mod.summary)\n",
    "\n",
    "    print(len(temp_df[\"pt\"].unique()), \"patients in this cancer type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequencies of vessel involvement by cancer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for idx, row in german_df.iterrows():\n",
    "    cancer_type = row[\"Cancer Type\"]\n",
    "\n",
    "    vessels = []\n",
    "\n",
    "    for vessel_idx in range(1, 5):\n",
    "        vessel_col = f\"Vessel {vessel_idx} involvement\"\n",
    "        if pd.notna(row[vessel_col]) and row[vessel_col] == 1:\n",
    "            if pd.isnull(row[f\"Vessel {vessel_idx} type\"]):\n",
    "                continue\n",
    "\n",
    "            vessels.append(row[f\"Vessel {vessel_idx} type\"])\n",
    "\n",
    "    for vessel in vessels:\n",
    "        id = (cancer_type, vessel)\n",
    "\n",
    "        if id not in counts:\n",
    "            counts[id] = 0\n",
    "\n",
    "        counts[id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unique_cancer_types = list(set([it[0] for it in counts]))\n",
    "unique_vessels = list(set([it[1] for it in counts]))\n",
    "\n",
    "heatmap = np.zeros((len(unique_cancer_types), len(unique_vessels)), dtype=int)\n",
    "\n",
    "for (cancer_type, vessel), count in counts.items():\n",
    "    cancer_type_idx = unique_cancer_types.index(cancer_type)\n",
    "    vessel_idx = unique_vessels.index(vessel)\n",
    "    heatmap[cancer_type_idx, vessel_idx] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "p = sns.clustermap(\n",
    "    heatmap.T,\n",
    "    cmap=\"vlag\",\n",
    "    center=0,\n",
    "    figsize=(6, 6),\n",
    "    yticklabels=unique_vessels,\n",
    "    xticklabels=unique_cancer_types,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vals = []\n",
    "labs = []\n",
    "\n",
    "for _idx, row in german_df.iterrows():\n",
    "    vessel_times = []\n",
    "\n",
    "    for vessel in range(1, 5):\n",
    "        vessel_col = f\"Vessel {vessel} involvement\"\n",
    "\n",
    "        if row[vessel_col] == 1:\n",
    "            imaging_time_cols = []\n",
    "\n",
    "            for imaging_idx in range(1, 10):\n",
    "                this_imaging_time_col = f\"Vessel {vessel} Imaging time {imaging_idx} time to involvement (days)\"\n",
    "                if this_imaging_time_col in row:\n",
    "                    imaging_time_cols.append(this_imaging_time_col)\n",
    "\n",
    "            final_imaging_time_col = (\n",
    "                f\"Vessel {vessel} LAST AVAILABLE STUDY time to involvement (days)\"\n",
    "            )\n",
    "\n",
    "            if final_imaging_time_col in row:\n",
    "                imaging_time_cols.append(final_imaging_time_col)\n",
    "\n",
    "            involvement_times = [\n",
    "                row[it] for it in imaging_time_cols if pd.notnull(row[it])\n",
    "            ]\n",
    "            earliest_involvement = min(involvement_times)\n",
    "\n",
    "            vessel_times.append((row[f\"Vessel {vessel} type\"], earliest_involvement))\n",
    "\n",
    "    earliest_vessel = None\n",
    "\n",
    "    if len(vessel_times) > 0:\n",
    "        min_time = min([it[1] for it in vessel_times])\n",
    "\n",
    "        vals.append(min_time / 365.25)\n",
    "        labs.append(row[\"Cancer Type\"])\n",
    "\n",
    "all_cancer_types = list(set(labs))\n",
    "\n",
    "dists = [[] for _ in all_cancer_types]\n",
    "\n",
    "for val, lab in zip(vals, labs):\n",
    "    dists[all_cancer_types.index(lab)].append(val)\n",
    "\n",
    "kruskal_result = kruskal(*dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "p = sns.boxplot(\n",
    "    x=labs, y=vals, saturation=0.8, color=\"white\", fliersize=0, **boxplot_props\n",
    ")\n",
    "b = sns.stripplot(\n",
    "    x=labs,\n",
    "    y=vals,\n",
    "    alpha=0.7,\n",
    "    size=6,\n",
    ")\n",
    "_ = plt.ylabel(\"Time to $V_1$ detection (yrs)\")\n",
    "\n",
    "_ = plt.title(\n",
    "    f\"Time to detection by cancer type\\nKruskal-Wallis p={kruskal_result.pvalue:.3e}\"\n",
    ")\n",
    "\n",
    "_ = plt.ylim((-0.5, 20))\n",
    "# make yticks linspace\n",
    "yticks = np.linspace(0, 20, 5)\n",
    "_ = plt.yticks(yticks)\n",
    "\n",
    "xticklabels = plt.xticks()[1]\n",
    "xticklabels = [it.get_text() for it in xticklabels]\n",
    "\n",
    "# set xticks\n",
    "x_tick_coords = []\n",
    "x_tick_labs = []\n",
    "\n",
    "groups = all_cancer_types\n",
    "\n",
    "for idx, group in enumerate(xticklabels):\n",
    "    group_split = \"\\n\".join(group.split())\n",
    "    x_tick_coords.append(idx)\n",
    "    x_tick_labs.append(\n",
    "        f\"{group_split}\\nn={len([v for idx, v in enumerate(vals) if labs[idx] == group])}\"\n",
    "    )\n",
    "\n",
    "_ = plt.xticks(x_tick_coords, x_tick_labs)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
